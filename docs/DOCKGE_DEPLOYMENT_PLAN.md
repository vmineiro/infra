# Plano: Deploy e ConfiguraÃ§Ã£o no Dockge + Gitea CI/CD

**Data**: 2026-01-05 (Updated)
**Contexto**: Recolha periÃ³dica de dados implementada + Gitea CI/CD configurado
**Objetivo**: Setup completo no Dockge + CI/CD automÃ¡tico com Gitea Actions

---

## ğŸ¯ Arquitetura Completa

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MacBook Air Server                                             â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Gitea         â”‚  â”‚   Dockge        â”‚  â”‚  BaseAnalysis  â”‚ â”‚
â”‚  â”‚   (Git+CI/CD)   â”‚  â”‚   (Mgmt UI)     â”‚  â”‚   (Staging)    â”‚ â”‚
â”‚  â”‚   Port: 3000    â”‚  â”‚   Port: 5001    â”‚  â”‚   Port: 8081   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚                                            â–²          â”‚
â”‚         â””â”€â”€â”€ Push triggers CI/CD â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â–²
                          â”‚ git push gitea main
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚ Dev Laptop     â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Workflow:**
1. Developer pushes code to Gitea
2. Gitea Actions runs tests automatically
3. If tests pass â†’ Auto-deploy to Dockge staging stack
4. Weekly ETL runs automatically (Sundays 10:00)

---

## Estado Atual

### âœ… O que estÃ¡ implementado (local)

**Phases 0-3 concluÃ­das**:
- âœ… Database migration `periodic_collection_log` table
- âœ… Date utilities (`get_previous_week_range()`)
- âœ… CLI argument `--periodic-update`
- âœ… Script `scripts/periodic_update.sh` com lock file
- âœ… Database logging (`log_periodic_execution()`)
- âœ… API timeout 300s configurado
- âœ… 21 unit tests (todos passam)

### âŒ O que falta

- âŒ Deploy para servidor (Dockge)
- âŒ ConfiguraÃ§Ã£o da scheduled task
- âŒ Testes em produÃ§Ã£o

---

## Infraestrutura Atual

**Servidor**:
- Dockge 1.5 a correr
- Pasta stacks: `~/Dev/docker-projects/dockge/stacks`
- Acesso SSH disponÃ­vel
- PostgreSQL (pode ser container ou externo)

**Projeto Local**:
- Path: `/Users/vitormineiro/Dev/VitorMineiro/BaseAnalysis/base-data-etl`
- Git repo: `git@github.com:vmineiro/base-data-etl.git`
- Docker files: `Dockerfile`, `docker-compose.yml`, `docker-compose.staging.yml` â† **Vamos usar este**

**Ambiente**: Staging

**Estrutura Final no Servidor**:
```
~/Dev/docker-projects/dockge/stacks/
â””â”€â”€ BaseAnalysis/                          â† Stack/Network (nome visÃ­vel no Dockge)
    â”œâ”€â”€ compose.yaml                       â† Dockge usa este (cÃ³pia do staging)
    â”œâ”€â”€ .env                               â† Environment variables
    â””â”€â”€ base-data-etl/                     â† RepositÃ³rio clonado
        â”œâ”€â”€ Dockerfile                     â† Build context aqui
        â”œâ”€â”€ docker-compose.staging.yml     â† Template original
        â”œâ”€â”€ source/
        â”œâ”€â”€ scripts/
        â””â”€â”€ ...
```

**IMPORTANTE**: O `compose.yaml` deve ter `context: ./base-data-etl` para apontar para o Dockerfile dentro do repo clonado.

---

## EstratÃ©gia Multi-Ambiente (Staging + Production)

Para correr mÃºltiplos ambientes no mesmo servidor, use **stacks separadas**:

```
~/Dev/docker-projects/dockge/stacks/
â”œâ”€â”€ BaseAnalysis-Staging/              â† Stack Staging
â”‚   â”œâ”€â”€ compose.yaml                   (cÃ³pia de docker-compose.staging.yml)
â”‚   â”œâ”€â”€ .env                           (variÃ¡veis staging)
â”‚   â””â”€â”€ base-data-etl/                 (cÃ³digo clonado)
â”‚
â””â”€â”€ BaseAnalysis-Production/           â† Stack Production (futuro)
    â”œâ”€â”€ compose.yaml                   (cÃ³pia de docker-compose.prod.yml)
    â”œâ”€â”€ .env                           (variÃ¡veis production)
    â””â”€â”€ base-data-etl/                 (cÃ³digo clonado ou partilhado)
```

**Vantagens**:
- Isolamento completo entre ambientes
- Portas diferentes (staging: 8081, prod: 8080)
- Service names iguais (`base-data-etl`) mas containers diferentes
- GestÃ£o independente via Dockge UI

**Como distinguir nos comandos**:

```bash
# STAGING
cd ~/Dev/docker-projects/dockge/stacks/BaseAnalysis-Staging
docker-compose exec base-data-etl python /app/source/main.py --periodic-update

# PRODUCTION
cd ~/Dev/docker-projects/dockge/stacks/BaseAnalysis-Production
docker-compose exec base-data-etl python /app/source/main.py --periodic-update

# OU usar container names (quando nÃ£o estÃ¡ no diretÃ³rio):
docker exec basedatafeed-staging-app python /app/source/main.py --periodic-update
docker exec basedatafeed-prod-app python /app/source/main.py --periodic-update
```

---

## Quick Start (TL;DR)

Para deployment rÃ¡pido no servidor:

```bash
# 1. Setup inicial (STAGING)
cd ~/Dev/docker-projects/dockge/stacks
mkdir -p BaseAnalysis-Staging && cd BaseAnalysis-Staging
git clone git@github.com:vmineiro/base-data-etl.git
cp base-data-etl/docker-compose.staging.yml compose.yaml
sed -i 's|context: \.|context: ./base-data-etl|g' compose.yaml

# 2. Criar .env file (copiar do exemplo abaixo, secÃ§Ã£o 1.3)
nano .env

# 3. No Dockge UI (http://server:5001):
#    - Stack "BaseAnalysis-Staging" deve aparecer automaticamente
#    - Click "Build" â†’ "Start"
#    - Criar scheduled task com cron: 0 10 * * 0
#    - Command: docker-compose exec -T base-data-etl python /app/source/main.py --periodic-update
#    - Working Directory: ~/Dev/docker-projects/dockge/stacks/BaseAnalysis-Staging
```

---

## Plano de Deployment

### Fase 1: PreparaÃ§Ã£o e Transfer (15-20 min)

#### 1.1 Verificar Estado Local

```bash
# No Mac (local)
cd /Users/vitormineiro/Dev/VitorMineiro/BaseAnalysis/base-data-etl

# Verificar que estÃ¡ tudo committed
git status

# Verificar testes passam
python -m pytest tests/test_date_utils.py -v

# Commit e push se houver mudanÃ§as
git add .
git commit -m "feat: add periodic data collection (Phases 0-3)"
git push origin main
```

#### 1.2 Preparar Servidor

```bash
# SSH para o servidor
ssh user@your-server.com

# Navegar para diretÃ³rio do Dockge
cd ~/Dev/docker-projects/dockge/stacks

# Criar diretÃ³rio para a stack BaseAnalysis-Staging
mkdir -p BaseAnalysis-Staging
cd BaseAnalysis-Staging

# Clonar repositÃ³rio ETL
git clone git@github.com:vmineiro/base-data-etl.git
# OU se usar HTTPS:
# git clone https://github.com/vmineiro/base-data-etl.git

# Criar compose.yaml a partir do docker-compose.staging.yml
cp base-data-etl/docker-compose.staging.yml compose.yaml

# IMPORTANTE: Editar compose.yaml para ajustar o build context
# Mudar de:
#   context: .
# Para:
#   context: ./base-data-etl
sed -i 's|context: \.|context: ./base-data-etl|g' compose.yaml

# IMPORTANTE: Alterar service name para base-data-etl
# Mudar de:
#   app-staging:
# Para:
#   base-data-etl:
sed -i 's|app-staging:|base-data-etl:|g' compose.yaml

# Estrutura resultante:
# ~/Dev/docker-projects/dockge/stacks/BaseAnalysis-Staging/
# â”œâ”€â”€ compose.yaml               â† Dockge usa este (context ajustado, service name correto!)
# â”œâ”€â”€ .env                       â† Criar no prÃ³ximo passo
# â””â”€â”€ base-data-etl/             â† CÃ³digo fonte
#     â”œâ”€â”€ Dockerfile            â† Build context aqui
#     â”œâ”€â”€ docker-compose.staging.yml  â† Template original
#     â”œâ”€â”€ source/
#     â””â”€â”€ ...
```

**Nota importante**: O Dockge 1.5 usa `compose.yaml` na raiz da stack. Copiamos o conteÃºdo do `docker-compose.staging.yml` para `compose.yaml` e ajustamos:
1. Build context para `./base-data-etl`
2. Service name para `base-data-etl` (consistente em todos os ambientes)

**Nota Multi-Ambiente**: Use `BaseAnalysis-Staging` para staging, `BaseAnalysis-Production` para produÃ§Ã£o. Isto permite correr ambos os ambientes simultaneamente no mesmo servidor.

**Alternativa (se nÃ£o usar Git)**:
```bash
# No Mac, fazer tar do projeto
cd /Users/vitormineiro/Dev/VitorMineiro/BaseAnalysis
tar -czf base-data-etl.tar.gz base-data-etl/

# Transfer via scp
scp base-data-etl.tar.gz user@server:~/Dev/docker-projects/dockge/stacks/

# No servidor, extrair
cd ~/Dev/docker-projects/dockge/stacks
mkdir -p BaseAnalysis
cd BaseAnalysis
tar -xzf ../base-data-etl.tar.gz
```

#### 1.3 Configurar Environment Variables

```bash
# No servidor, criar .env file na raiz da stack
cd ~/Dev/docker-projects/dockge/stacks/BaseAnalysis-Staging

cat > .env << 'EOF'
# Database Configuration
DATABASE_HOST=base-data-service-base-data.j.aivencloud.com
DATABASE_PORT=10091
DATABASE_NAME=basedata
DATABASE_USER=dev_api
DATABASE_PASSWORD=<REDACTED_AIVEN_PASSWORD>
DATABASE_SSL_MODE=prefer
DATABASE_CONNECT_TIMEOUT=30
DATABASE_COMMAND_TIMEOUT=300

# Application Configuration
BASEDATAFEED_BATCH_SIZE=50
BASEDATAFEED_ENABLE_VALIDATION=true
BASEDATAFEED_MAX_CONCURRENT_REQUESTS=5
DATE_RANGE_DAYS=7

# Logging
BASEDATAFEED_LOG_LEVEL=INFO
EOF

# Proteger o ficheiro (contÃ©m passwords)
chmod 600 .env
```

**âš ï¸ IMPORTANTE**: Se a database for container no Dockge, usar nome do service em vez de host externo.

---

### Fase 2: Configurar Stack no Dockge (10 min)

#### 2.1 Adicionar Stack via Dockge UI

**Dockge 1.5 - Auto-Discovery**:

1. Abrir Dockge UI no browser: `http://your-server:5001`

2. A stack **BaseAnalysis** deve aparecer automaticamente na lista de stacks
   - Dockge 1.5 detecta automaticamente diretÃ³rios com `compose.yaml` em `~/Dev/docker-projects/dockge/stacks/`
   - O nome da stack Ã© o nome do diretÃ³rio (`BaseAnalysis`)

3. Se nÃ£o aparecer:
   - Verificar que `compose.yaml` existe em `~/Dev/docker-projects/dockge/stacks/BaseAnalysis/`
   - Refresh da pÃ¡gina do Dockge
   - Verificar logs do Dockge: `docker logs dockge`

4. Click na stack `BaseAnalysis` para ver os detalhes

#### 2.2 ConfiguraÃ§Ã£o do Compose File

O ficheiro `compose.yaml` (copiado de `docker-compose.staging.yml`) jÃ¡ deve conter a configuraÃ§Ã£o correta para o ambiente de staging. Exemplo de estrutura esperada:

```yaml
# compose.yaml (exemplo de estrutura)
services:
  app:
    build:
      context: ./base-data-etl    # â† Importante: aponta para o repo clonado
      dockerfile: Dockerfile
    container_name: base-data-etl
    restart: always
    env_file: .env
    volumes:
      - ./logs:/var/log/base-etl
    depends_on:
      - db  # Se database for container
    networks:
      - base-network

  # Se PostgreSQL for container (opcional)
  db:
    image: postgres:15-alpine
    container_name: base-postgres
    restart: always
    environment:
      POSTGRES_DB: basedata
      POSTGRES_USER: dev_api
      POSTGRES_PASSWORD: ${DATABASE_PASSWORD}
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - base-network

networks:
  base-network:
    driver: bridge

volumes:
  postgres-data:
```

#### 2.3 Build e Start via Dockge

**Na UI do Dockge**:
1. Selecionar stack `BaseAnalysis`
2. Click "Build" (constrÃ³i a imagem)
3. Aguardar build completar (pode demorar 2-5 min)
4. Click "Start" ou "Up"
5. Verificar logs na UI

**Via CLI (alternativa)**:
```bash
cd ~/Dev/docker-projects/dockge/stacks/BaseAnalysis
docker-compose up --build -d
```

---

### Fase 3: Verificar Deployment (10 min)

#### 3.1 Health Checks

```bash
# Verificar containers estÃ£o a correr
docker ps | grep base

# Ver logs (via docker-compose)
cd ~/Dev/docker-projects/dockge/stacks/BaseAnalysis-Staging
docker-compose logs -f base-data-etl

# OU via container name
docker logs basedatafeed-staging-app --tail 50

# Verificar entrypoint executou corretamente
docker logs basedatafeed-staging-app | grep "âœ“"
# Deve mostrar:
# âœ“ Database connection successful
# âœ“ Health check passed
```

#### 3.2 Verificar Database Connection

```bash
# Executar dentro do container (via docker-compose)
cd ~/Dev/docker-projects/dockge/stacks/BaseAnalysis-Staging
docker-compose exec base-data-etl python -c "
from source.database.database_manager import DatabaseManager
db = DatabaseManager()
print('âœ“ Database connection OK')
db.close()
"

# OU via container name
docker exec -it basedatafeed-staging-app python -c "
from source.database.database_manager import DatabaseManager
db = DatabaseManager()
print('âœ“ Database connection OK')
db.close()
"
```

#### 3.3 Verificar Migrations

```bash
# Verificar que periodic_collection_log table existe (via docker-compose)
cd ~/Dev/docker-projects/dockge/stacks/BaseAnalysis-Staging
docker-compose exec base-data-etl psql -U dev_api -d basedata -c "\d dbo.periodic_collection_log"

# OU via container name
docker exec -it basedatafeed-staging-db psql -U dev_api -d basedata -c "\d dbo.periodic_collection_log"

# Deve mostrar estrutura da tabela:
# id, week_start, week_end, execution_date, status, contracts_processed, contracts_failed, error_message
```

---

### Fase 4: Configurar Scheduled Task no Dockge (5 min)

#### 4.1 Testar Comando Manual Primeiro

```bash
# No servidor, testar comando (via docker-compose - RECOMENDADO)
cd ~/Dev/docker-projects/dockge/stacks/BaseAnalysis-Staging
docker-compose exec base-data-etl python /app/source/main.py --periodic-update

# OU via container name direto
docker exec basedatafeed-staging-app python /app/source/main.py --periodic-update
```

**SaÃ­da esperada**:
```
ğŸ“… Periodic Update Mode: Processing previous week (2025-11-17 to 2025-11-23)
Processing date range: 2025-11-17 to 2025-11-23
...
âœ“ Completed processing date range
```

#### 4.2 Verificar Database Logging

```bash
# Via docker-compose
cd ~/Dev/docker-projects/dockge/stacks/BaseAnalysis-Staging
docker-compose exec -T base-data-etl psql -U dev_api -d basedata -c "
SELECT
    week_start,
    week_end,
    status,
    contracts_processed,
    execution_date
FROM dbo.periodic_collection_log
ORDER BY execution_date DESC
LIMIT 5;
"

# OU via container name
docker exec -it basedatafeed-staging-db psql -U dev_api -d basedata -c "
SELECT
    week_start,
    week_end,
    status,
    contracts_processed,
    execution_date
FROM dbo.periodic_collection_log
ORDER BY execution_date DESC
LIMIT 5;
"
```

**Deve mostrar entrada recente**.

#### 4.3 Criar Scheduled Task no Dockge

**Na UI do Dockge**:

1. **Navegar para a Stack**:
   - Abrir stack `BaseAnalysis`

2. **Criar Task/Pipeline**:
   - Procurar secÃ§Ã£o "Tasks", "Pipelines", ou "Cron Jobs" (varia conforme versÃ£o Dockge)
   - Click "Add Task" ou "New Pipeline"

3. **Configurar Task**:
   ```yaml
   Name: Periodic Data Collection
   Description: Weekly data collection (Sunday-Saturday) from BASE.gov.pt

   Schedule: 0 10 * * 0
   # Formato cron: minuto hora dia mÃªs dia-da-semana
   # 0 10 * * 0 = Domingo Ã s 10:00

   Command: docker-compose exec -T base-data-etl python /app/source/main.py --periodic-update

   # Alternativa usando container name:
   # Command: docker exec basedatafeed-staging-app python /app/source/main.py --periodic-update

   Working Directory: ~/Dev/docker-projects/dockge/stacks/BaseAnalysis-Staging

   Enabled: âœ“ (checked)
   ```

4. **Flags Importantes**:
   - `-T` flag: Desativa TTY allocation (necessÃ¡rio para cron/scheduled execution)
   - Sem este flag, pode dar erro em execuÃ§Ã£o agendada

#### 4.4 Testar Trigger Manual

1. Na UI do Dockge, na task criada
2. Click "Run Now" ou "Trigger" ou â–¶ï¸ (varia conforme versÃ£o)
3. Monitorizar logs na UI
4. Verificar database:

```bash
# Via docker-compose
cd ~/Dev/docker-projects/dockge/stacks/BaseAnalysis-Staging
docker-compose exec -T base-data-etl psql -U dev_api -d basedata -c "
SELECT * FROM dbo.periodic_collection_log ORDER BY execution_date DESC LIMIT 3;
"

# OU via container name
docker exec -it basedatafeed-staging-db psql -U dev_api -d basedata -c "
SELECT * FROM dbo.periodic_collection_log ORDER BY execution_date DESC LIMIT 3;
"
```

---

### Fase 4.4: CI/CD com Gitea + Gitea Actions (âœ… IMPLEMENTADO)

#### Por que Gitea em vez de Cron Manual?

O Dockge 1.5 **nÃ£o tem funcionalidade nativa de scheduled tasks**. As alternativas eram:

1. **Cron manual no servidor** (OpÃ§Ã£o bÃ¡sica)
2. **Gitea + Gitea Actions** (âœ… **IMPLEMENTADO** - leve e eficiente)
3. **GitLab CE Self-Hosted** (Muito pesado: 4-8GB RAM - âŒ FALHOU)

**Por que Gitea foi escolhido**:

âœ… **Leve**: ~450MB RAM total (vs 4-8GB do GitLab)
âœ… **GitHub Actions compatible**: Usa mesma sintaxe de workflows
âœ… **Multi-projeto**: Cada projeto tem repositÃ³rio e pipelines prÃ³prios
âœ… **Scheduling visual**: Configure schedules na UI web
âœ… **Pipeline history**: Logs completos de todas as execuÃ§Ãµes
âœ… **CI/CD integrado**: Testes automÃ¡ticos antes de deploy
âœ… **Git hosting self-hosted**: Sem dependÃªncias externas
âœ… **RÃ¡pido**: ExecuÃ§Ã£o local, sem latÃªncia de SSH

**Recursos** (medidos):
- Gitea Server: ~300MB RAM
- Gitea Actions Runner: ~150MB RAM
- Total: ~450MB RAM (aceitÃ¡vel em MacBook Air 8GB)

#### Setup Gitea + Actions no Servidor

**1. Instalar Gitea via Docker Compose**:

Ver guia completo em: **`gitea-setup/README.md`**

```bash
# No servidor MacBook Air
mkdir -p ~/Dev/gitea
cd ~/Dev/gitea

# Copiar docker-compose.yml do gitea-setup/docker-compose.yml
# (veja o ficheiro para configuraÃ§Ã£o completa)

# Iniciar Gitea
docker-compose up -d gitea

# Aguardar ~30s para Gitea inicializar
# Acessar: http://localhost:3000 (ou http://[server-ip]:3000)
# Completar setup wizard (criar admin user)
```

**2. Registar Gitea Actions Runner**:

```bash
# No Gitea UI:
# Site Administration â†’ Actions â†’ Runners â†’ Create new Runner
# Copiar registration token

# Iniciar runner
cd ~/Dev/gitea
docker-compose up -d gitea-runner

# Registar runner manualmente
docker exec -it gitea-runner act_runner register \
  --instance http://gitea:3000 \
  --token <PASTE_YOUR_TOKEN_HERE> \
  --name macbook-air-runner

# Restart runner
docker-compose restart gitea-runner

# Verificar status: Gitea UI â†’ Actions â†’ Runners
# Deve aparecer "macbook-air-runner" com status "Idle" (verde)
```

**3. Migrar base-data-etl para Gitea**:

```bash
# No laptop de desenvolvimento
cd /Users/vitormineiro/Dev/VitorMineiro/BaseAnalysis/base-data-etl

# Adicionar remote do Gitea (mantÃ©m GitHub/origin como backup)
git remote add gitea http://[macbook-air-ip]:3000/<username>/base-data-etl.git

# Push para Gitea
git push gitea main

# Verificar no Gitea UI - cÃ³digo deve aparecer
```

**4. Workflows CI/CD (jÃ¡ criados no projeto)**:

Os workflows jÃ¡ estÃ£o implementados em `.github/workflows/`:

**a) `ci-cd.yml`** - Pipeline principal (automÃ¡tico em push):
- âœ… Run pytest tests
- âœ… Auto-deploy to staging (se tests pass)
- âœ… Health check verification

**b) `scheduled-etl.yml`** - ETL agendado:
- âœ… Cron: Domingos 10:00 AM
- âœ… Executa periodic update
- âœ… Verifica database update
- âœ… Manual trigger disponÃ­vel

**c) `scripts/deploy-staging.sh`** - Script de deployment:
- âœ… Pull latest code
- âœ… Rebuild containers
- âœ… Verify health status
- âœ… Rollback on failure

**5. Como funciona o workflow automÃ¡tico**:

```
Developer Laptop                MacBook Air Server
      â”‚                                â”‚
      â”‚  git push gitea main           â”‚
      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>
      â”‚                                â”‚
      â”‚                         â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
      â”‚                         â”‚ Gitea       â”‚
      â”‚                         â”‚ detects pushâ”‚
      â”‚                         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
      â”‚                                â”‚
      â”‚                         â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
      â”‚                         â”‚Gitea Runner â”‚
      â”‚                         â”‚runs workflowâ”‚
      â”‚                         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
      â”‚                                â”‚
      â”‚                         â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
      â”‚                         â”‚1. Run Tests â”‚
      â”‚                         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
      â”‚                                â”‚
      â”‚                         â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
      â”‚                         â”‚2. Deploy    â”‚
      â”‚                         â”‚   Staging   â”‚
      â”‚                         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
      â”‚                                â”‚
      â”‚  View results in Gitea UI      â”‚
      <â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
```

**6. Configurar Schedule (jÃ¡ configurado no workflow)**:

O schedule jÃ¡ estÃ¡ definido em `scheduled-etl.yml`:
```yaml
on:
  schedule:
    - cron: '0 10 * * 0'  # Domingos Ã s 10:00 UTC
```

Para trigger manual:
1. Gitea UI â†’ Repository â†’ Actions
2. Select "Scheduled ETL" workflow
3. Click "Run workflow"

Isto **substitui completamente a necessidade de cron jobs no servidor**!

#### BenefÃ­cios para MÃºltiplos Projetos

Quando adicionar mais projetos:
1. Criar novo repositÃ³rio no Gitea
2. Adicionar workflows `.github/workflows/` ao projeto
3. Configurar schedule no workflow YAML
4. Gitea Actions executa tudo automaticamente

**Exemplo**: Se tiver 5 projetos ETL, cada um tem seus prÃ³prios workflows, schedules, e logs centralizados no Gitea.

#### Recursos do Gitea

- **Web UI**: `http://[server-ip]:3000`
- **Recursos**: ~450MB RAM (muito mais leve que GitLab)
- **Custo**: Gitea Ã© gratuito e open-source
- **DocumentaÃ§Ã£o**: https://docs.gitea.com/

---

### Fase 5: MonitorizaÃ§Ã£o e ValidaÃ§Ã£o (10 min)

#### 5.1 Schedule de Testes

Para nÃ£o esperar atÃ© Domingo, testar com schedule mais frequente:

```
# Teste: A cada 5 minutos (temporÃ¡rio)
*/5 * * * *

# Teste: Todos os dias Ã s 14:00
0 14 * * *

# ProduÃ§Ã£o: Domingo Ã s 10:00
0 10 * * 0
```

**Depois de validar, voltar a schedule de produÃ§Ã£o!**

#### 5.2 Verificar ExecuÃ§Ã£o Agendada

**Aguardar prÃ³xima execuÃ§Ã£o** (baseado no schedule de teste), depois:

```bash
# Verificar logs da task no Dockge UI
# OU via CLI:
cd ~/Dev/docker-projects/dockge/stacks/BaseAnalysis-Staging
docker-compose logs base-data-etl | grep "Periodic Update Mode"

# Ou via container name:
docker logs basedatafeed-staging-app | grep "Periodic Update Mode"

# Verificar database
docker-compose exec -T base-data-etl psql -U dev_api -d basedata -c "
SELECT
    week_start,
    week_end,
    status,
    contracts_processed,
    contracts_failed,
    execution_date
FROM dbo.periodic_collection_log
ORDER BY execution_date DESC
LIMIT 10;
"
```

#### 5.3 Verificar Gap Detection

```bash
# Via docker-compose
cd ~/Dev/docker-projects/dockge/stacks/BaseAnalysis-Staging
docker-compose exec -T base-data-etl psql -U dev_api -d basedata -c "
WITH expected_weeks AS (
    SELECT generate_series(
        date_trunc('week', CURRENT_DATE - INTERVAL '3 months'),
        date_trunc('week', CURRENT_DATE - INTERVAL '1 week'),
        '1 week'::interval
    )::date AS week_start
)
SELECT
    ew.week_start AS missing_week_start,
    ew.week_start + 6 AS missing_week_end,
    '7 days'::text AS duration
FROM expected_weeks ew
LEFT JOIN dbo.periodic_collection_log pcl ON ew.week_start = pcl.week_start
WHERE pcl.id IS NULL
ORDER BY ew.week_start DESC;
"
```

Se houver gaps (semanas em falta), processar manualmente:

```bash
# Processar semana especÃ­fica (via docker-compose)
cd ~/Dev/docker-projects/dockge/stacks/BaseAnalysis-Staging
docker-compose exec base-data-etl python /app/source/main.py \
  --start-date 2025-11-17 \
  --end-date 2025-11-23 \
  --data-type both

# OU via container name
docker exec basedatafeed-staging-app python /app/source/main.py \
  --start-date 2025-11-17 \
  --end-date 2025-11-23 \
  --data-type both
```

---

## Setup ProduÃ§Ã£o (Quando Chegar a Altura)

### 1. Criar Stack de ProduÃ§Ã£o

```bash
# No servidor
cd ~/Dev/docker-projects/dockge/stacks
mkdir -p BaseAnalysis-Production
cd BaseAnalysis-Production

# Clonar cÃ³digo (ou criar symlink para staging)
git clone git@github.com:vmineiro/base-data-etl.git

# Copiar docker-compose de produÃ§Ã£o
cp base-data-etl/docker-compose.prod.yml compose.yaml

# Ajustar build context
sed -i '' 's|context: \.|context: ./base-data-etl|g' compose.yaml

# Ajustar service name se necessÃ¡rio
sed -i '' 's|app-prod:|base-data-etl:|g' compose.yaml

# Criar .env para produÃ§Ã£o
nano .env
```

### 2. Configurar .env de ProduÃ§Ã£o

```env
# Database Configuration (PRODUÃ‡ÃƒO)
BASEDATAFEED_DB_HOST=prod-db-host  # â† Diferente de staging
BASEDATAFEED_DB_PORT=5432
BASEDATAFEED_DB_NAME=basedata-prod
BASEDATAFEED_DB_USER=prod_user
BASEDATAFEED_DB_PASSWORD=prod_password_secure

# Application Configuration
BASEDATAFEED_ENVIRONMENT=production  # â† production
BASEDATAFEED_LOG_LEVEL=WARNING       # â† menos verboso que staging
BASEDATAFEED_DEBUG="false"

# Processing Configuration
BASEDATAFEED_BATCH_SIZE=100          # â† pode ser maior em prod
BASEDATAFEED_MAX_CONCURRENT_REQUESTS=20
```

### 3. Deploy no Dockge

1. Dockge UI detecta automaticamente `BaseAnalysis-Production`
2. Build â†’ Start
3. Verificar logs
4. Configurar scheduled task separado para prod (ou usar GitLab schedule)

### 4. Isolamento e SeguranÃ§a

**Portas diferentes**:
- Staging: 8081, 5433, 5051
- Production: 8080, 5432, 5050

**Networks diferentes** (opcional):
```yaml
networks:
  base-analytics-prod:
    name: base-analytics-prod
```

**Recursos diferentes**:
- Staging: 1.5 CPU, 1.5GB RAM
- Production: 2 CPU, 3GB RAM

**Backup apenas prod**:
```bash
# Cron para backup automÃ¡tico apenas da produÃ§Ã£o
0 3 * * * docker exec basedatafeed-prod-db pg_dump -U prod_user basedata-prod > /backups/basedata-$(date +\%Y\%m\%d).sql
```

### 5. GitLab CI/CD para ProduÃ§Ã£o

Se usar GitLab, adicionar job de deploy para produÃ§Ã£o no `.gitlab-ci.yml`:

```yaml
# Deploy para production (manual approval)
deploy-production:
  stage: deploy
  script:
    - cd ~/Dev/docker-projects/dockge/stacks/BaseAnalysis-Production
    - docker-compose pull
    - docker-compose up -d --build
  only:
    - main
  environment:
    name: production
  when: manual  # Requer aprovaÃ§Ã£o manual
  tags:
    - shell

# Scheduled ETL para production
etl-periodic-prod:
  stage: deploy
  script:
    - cd ~/Dev/docker-projects/dockge/stacks/BaseAnalysis-Production
    - docker-compose exec -T base-data-etl python /app/source/main.py --periodic-update
  only:
    - schedules
  environment:
    name: production
  tags:
    - shell
```

Criar schedule separado no GitLab para produÃ§Ã£o (mesmo horÃ¡rio ou diferente).

---

## Troubleshooting

### Problema 1: Container nÃ£o inicia

**Sintomas**: Container fica em estado "restarting" ou "exited"

**Debug**:
```bash
# Ver logs completos (via docker-compose)
cd ~/Dev/docker-projects/dockge/stacks/BaseAnalysis-Staging
docker-compose logs base-data-etl

# OU via container name
docker logs basedatafeed-staging-app

# Ver Ãºltimo erro
docker logs basedatafeed-staging-app --tail 100 | grep -i error

# Verificar entrypoint
docker run --rm base-data-etl cat /app/entrypoint.sh
```

**SoluÃ§Ãµes comuns**:
- Database credentials erradas â†’ verificar `.env`
- Database nÃ£o acessÃ­vel â†’ verificar network/firewall
- Migrations falharam â†’ verificar SQL syntax

### Problema 2: Scheduled task nÃ£o executa

**Debug**:
```bash
# Verificar schedule no Dockge UI
# Verificar logs do Dockge (podem estar em /var/log/dockge ou similar)

# Testar comando manualmente (via docker-compose)
cd ~/Dev/docker-projects/dockge/stacks/BaseAnalysis-Staging
docker-compose exec base-data-etl python /app/source/main.py --periodic-update

# OU via container name
docker exec basedatafeed-staging-app python /app/source/main.py --periodic-update
```

**SoluÃ§Ãµes comuns**:
- Cron syntax errado â†’ validar em https://crontab.guru
- Flag `-T` em falta â†’ adicionar ao comando
- Working directory errado â†’ especificar path completo

### Problema 3: API timeout (>300s)

**Sintomas**: Logs mostram "timeout after 300s"

**SoluÃ§Ãµes**:
- JÃ¡ configurado para 300s no `config.ini`
- Se ainda assim timeout, dividir em ranges mais pequenos
- Verificar network latency para API BASE.gov.pt

### Problema 4: Lock file persiste

**Sintomas**: ExecuÃ§Ã£o falha com "Another instance is already running"

**SoluÃ§Ã£o**:
```bash
# Remover lock file manualmente (via docker-compose)
cd ~/Dev/docker-projects/dockge/stacks/BaseAnalysis-Staging
docker-compose exec base-data-etl rm -f /tmp/periodic_update.lock

# OU via container name
docker exec basedatafeed-staging-app rm -f /tmp/periodic_update.lock

# Verificar se processo realmente estÃ¡ a correr
docker-compose exec base-data-etl ps aux | grep python
```

---

## OperaÃ§Ãµes do Dia-a-Dia

### Update de CÃ³digo

**Staging**:
```bash
# No servidor
cd ~/Dev/docker-projects/dockge/stacks/BaseAnalysis-Staging/base-data-etl
git pull origin main

# No Dockge UI:
# 1. Stop stack BaseAnalysis-Staging
# 2. Build (reconstrÃ³i imagem)
# 3. Start stack
```

**Production**:
```bash
# No servidor
cd ~/Dev/docker-projects/dockge/stacks/BaseAnalysis-Production/base-data-etl
git pull origin main

# No Dockge UI:
# 1. Stop stack BaseAnalysis-Production
# 2. Build (reconstrÃ³i imagem)
# 3. Start stack
```

### Ver HistÃ³rico de ExecuÃ§Ãµes

**Via Database**:
```sql
SELECT
    week_start,
    week_end,
    status,
    contracts_processed,
    contracts_failed,
    ROUND(
        (contracts_processed::numeric / NULLIF(contracts_processed + contracts_failed, 0) * 100),
        2
    ) AS success_rate_pct,
    execution_date
FROM dbo.periodic_collection_log
ORDER BY execution_date DESC
LIMIT 20;
```

**Via Dockge UI**:
- Ver histÃ³rico da task em "Execution History" ou "Logs"

### Trigger Manual

**Via Dockge UI**:
- Click no botÃ£o "Run Now" ou "Trigger" na task

**Via CLI - Staging**:
```bash
cd ~/Dev/docker-projects/dockge/stacks/BaseAnalysis-Staging
docker-compose exec base-data-etl python /app/source/main.py --periodic-update

# OU via container name
docker exec basedatafeed-staging-app python /app/source/main.py --periodic-update
```

**Via CLI - Production**:
```bash
cd ~/Dev/docker-projects/dockge/stacks/BaseAnalysis-Production
docker-compose exec base-data-etl python /app/source/main.py --periodic-update

# OU via container name
docker exec basedatafeed-prod-app python /app/source/main.py --periodic-update
```

### Alterar Schedule

**Via Dockge UI**:
1. Editar task
2. Alterar campo "Schedule"
3. Guardar

**Schedules Ãºteis**:
- `0 10 * * 0` - Domingo 10:00 (produÃ§Ã£o)
- `0 10 * * 1` - Segunda 10:00
- `0 2 * * *` - Todos os dias 02:00
- `0 10 * * 0,3` - Domingo e Quarta 10:00

---

## Checklist Final

### Deployment
- [ ] CÃ³digo transferido para servidor
- [ ] `.env` criado com credentials corretos
- [ ] Stack adicionada no Dockge
- [ ] Build concluÃ­do com sucesso
- [ ] Containers a correr (`docker ps`)
- [ ] Database connection OK
- [ ] Migrations aplicadas

### Scheduled Task
- [ ] Comando testado manualmente
- [ ] Database logging funciona
- [ ] Task criada no Dockge
- [ ] Schedule configurado (`0 10 * * 0`)
- [ ] Trigger manual testado
- [ ] Primeira execuÃ§Ã£o agendada OK

### ValidaÃ§Ã£o
- [ ] Logs acessÃ­veis no Dockge UI
- [ ] Database tem registos de execuÃ§Ã£o
- [ ] Gap detection query funciona
- [ ] Lock file mechanism funciona

### ProduÃ§Ã£o
- [ ] Schedule de teste alterado para produÃ§Ã£o
- [ ] MonitorizaÃ§Ã£o configurada (opcional)
- [ ] Alertas configurados (opcional)
- [ ] README.md atualizado
- [ ] CURRENT_FOCUS.md atualizado

---

## PrÃ³ximos Passos (Opcional)

### MonitorizaÃ§Ã£o
- Setup Uptime Kuma (ou similar) para monitorizar stack
- Alertas se Ãºltima execuÃ§Ã£o > 8 dias
- Slack/Email notifications em failures

### Logs
- Configurar log rotation para `/var/log/base-etl/periodic.log`
- Integrar com sistema de logging centralizado (Loki, etc)

### Backups
- Backup automÃ¡tico da database
- Snapshot antes de updates

---

## Estimativas de Tempo

| Fase | DescriÃ§Ã£o | Tempo |
|------|-----------|-------|
| 1 | PreparaÃ§Ã£o e transfer | 15-20 min |
| 2 | Configurar stack no Dockge | 10 min |
| 3 | Verificar deployment | 10 min |
| 4 | Configurar scheduled task | 5 min |
| 5 | MonitorizaÃ§Ã£o e validaÃ§Ã£o | 10 min |
| **TOTAL** | **Setup completo** | **50-55 min** |

**Tempo adicional para troubleshooting**: +10-20 min

---

## Recursos

### Comandos Ãšteis

**Staging**:
```bash
# Ver logs em tempo real (via docker-compose)
cd ~/Dev/docker-projects/dockge/stacks/BaseAnalysis-Staging
docker-compose logs -f base-data-etl

# OU via container name
docker logs -f basedatafeed-staging-app

# Entrar no container
docker-compose exec base-data-etl bash
# OU: docker exec -it basedatafeed-staging-app bash

# Verificar status
docker ps -a | grep basedatafeed-staging

# Reiniciar container
docker-compose restart base-data-etl
# OU: docker restart basedatafeed-staging-app

# Ver uso de recursos
docker stats basedatafeed-staging-app
```

**Production**:
```bash
# Ver logs em tempo real
cd ~/Dev/docker-projects/dockge/stacks/BaseAnalysis-Production
docker-compose logs -f base-data-etl

# OU via container name
docker logs -f basedatafeed-prod-app

# Entrar no container
docker-compose exec base-data-etl bash
# OU: docker exec -it basedatafeed-prod-app bash

# Verificar status
docker ps -a | grep basedatafeed-prod

# Reiniciar container
docker-compose restart base-data-etl
# OU: docker restart basedatafeed-prod-app

# Ver uso de recursos
docker stats basedatafeed-prod-app
```

### SQL Queries Ãšteis

```sql
-- EstatÃ­sticas gerais
SELECT
    COUNT(*) AS total_executions,
    COUNT(*) FILTER (WHERE status = 'completed') AS successful,
    COUNT(*) FILTER (WHERE status = 'failed') AS failed,
    SUM(contracts_processed) AS total_contracts,
    ROUND(AVG(contracts_processed), 2) AS avg_per_week
FROM dbo.periodic_collection_log;

-- Ãšltima execuÃ§Ã£o
SELECT * FROM dbo.periodic_collection_log
ORDER BY execution_date DESC LIMIT 1;
```

---

**Fim do Plano** âœ“
